{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowMindBot import *\n",
    "from TowerDefense import *\n",
    "from TowerDefenseApi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "towerDefense = TowerDefense('state.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TowerDefenseApi(towerDefense.getGameState())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ShallowMindBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected action type 2 from options [0, 1, 2, 6] with probabilities [0.24234084 0.24830685 0.25839406 0.25095826]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4,0,2'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.doTurn(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_actions = [0,1,2,6]\n",
    "p, h = bot.policy_forward(bot.computeStateFeatures(api), possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24234084, 0.24830685, 0.25839406, 0.25095826])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_action = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8721813 , 0.        , 0.        , 1.53647372, 0.        ,\n",
       "       3.83066152, 0.        , 0.        , 1.03934245, 0.03170608,\n",
       "       0.        , 0.        , 7.01988837, 0.        , 0.52261405])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 # used to perform a RMS prop param update every batch_size steps\n",
    "learning_rate = 1e-3 # learning rate used in RMS prop\n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POSSIBLE_ACTIONS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_grad(softmax):\n",
    "    s = softmax.reshape(-1,1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18361176, -0.06017489, -0.06261943, -0.06081743])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_action = 0\n",
    "dsoftmax = softmax_grad(p)[selected_action,:]\n",
    "dsoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24234084, -0.24830685,  0.74160594, -0.25095826])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog = dsoftmax / p[selected_action]\n",
    "dlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([float(val) for val in bot.computeStateFeatures(api).values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.000e+01,  3.500e+02,  1.000e+02,  1.500e+01,  8.500e+01,\n",
       "        5.200e+01,  1.300e+01,  3.900e+01,  2.081e+03,  0.000e+00,\n",
       "        0.000e+00,  5.000e+00,  6.000e+00,  4.000e+00,  1.000e+00,\n",
       "        1.000e+00, -2.000e+01, -2.000e+01,  0.000e+00,  0.000e+00,\n",
       "        1.000e+00,  0.000e+00,  8.000e+00,  0.000e+00,  1.400e+01,\n",
       "        0.000e+00,  6.000e+00,  3.000e+00])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24234084, -0.24830685,  0.74160594,  0.        ,  0.        ,\n",
       "        0.        , -0.25095826])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in dlog with zeros at the actions that were not possible\n",
    "dlog_filled = np.zeros(NUM_ACTION_TYPES)\n",
    "dlog_filled[possible_actions] = dlog\n",
    "dlog_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlog_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45370598, -0.        , -0.        , -0.37235033, -0.        ,\n",
       "        -0.92832572, -0.        , -0.        , -0.25187512, -0.00768368,\n",
       "        -0.        , -0.        , -1.70120562, -0.        , -0.12665073],\n",
       "       [-0.46487544, -0.        , -0.        , -0.38151694, -0.        ,\n",
       "        -0.95117948, -0.        , -0.        , -0.25807585, -0.00787284,\n",
       "        -0.        , -0.        , -1.74308634, -0.        , -0.12976865],\n",
       "       [ 1.38842078,  0.        ,  0.        ,  1.13945804,  0.        ,\n",
       "         2.84084134,  0.        ,  0.        ,  0.77078254,  0.02351342,\n",
       "         0.        ,  0.        ,  5.20599092,  0.        ,  0.38757368],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.46983936, -0.        , -0.        , -0.38559077, -0.        ,\n",
       "        -0.96133614, -0.        , -0.        , -0.26083157, -0.0079569 ,\n",
       "        -0.        , -0.        , -1.76169896, -0.        , -0.13115431]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take outer product to get gradW2\n",
    "grad_W2 = dlog_filled[None,:].T.dot(h[None,:])\n",
    "# Confirm that the grad is 0 for the forbidden actions\n",
    "grad_W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 15)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.model['W2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 15)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradW2(p, possible_actions, selected_action, h):\n",
    "    dsoftmax = softmax_grad(p)[selected_action,:]\n",
    "    dlog = dsoftmax / p[selected_action]\n",
    "    # Fill in dlog with zeros at the actions that were not possible\n",
    "    dlog_filled = np.zeros(NUM_ACTION_TYPES)\n",
    "    dlog_filled[possible_actions] = dlog\n",
    "    dW2 = dlog_filled[None,:].T.dot(h[None,:])\n",
    "    return dW2, dlog_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradW2, dlog_filled = gradW2(p, possible_actions, selected_action, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradW1(dlog_filled, W2, h, x):\n",
    "    dh = W2.T.dot(dlog_filled)\n",
    "    dh[h<=0] = 0\n",
    "    dW1 = np.outer(dh,x)\n",
    "    return dW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradw1 = gradW1(dlog_filled, bot.model['W2'], h, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_backward(self, eph, epx, eplogp, eppossactions):\n",
    "    \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "    \"\"\" Manual implementation of a backward prop\"\"\"\n",
    "    \"\"\" It takes an array of the hidden states that corresponds to all the images that were\n",
    "    fed to the NN (for the entire episode, so a bunch of games) and their corresponding logp\"\"\"\n",
    "    eplogp_filled = np.zeros(NUM_POSSIBLE_ACTIONS)\n",
    "    eplogp_filled[epossactions] = eplogp\n",
    "    dW2 = np.dot(eph.T, eplogp).ravel()\n",
    "    dh = np.outer(eplogp, self.model['W2'])\n",
    "    dh[eph <= 0] = 0 # backpro prelu\n",
    "    dW1 = np.dot(dh.T, epx)\n",
    "    return {'W1':dW1, 'W2':dW2}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
