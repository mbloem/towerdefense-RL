{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowMindBot import *\n",
    "from TowerDefense import *\n",
    "from TowerDefenseApi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "towerDefense = TowerDefense('state.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TowerDefenseApi(towerDefense.getGameState())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ShallowMindBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected action type 4 from options [0, 1, 2, 4, 6] with probabilities [0.21018274 0.19952657 0.19744639 0.19700019 0.1958441 ]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\logs\\\\game_-1\\\\round_74.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dce77b876d8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoTurn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Nerdfest\\src\\shallowmind\\shallowmind_v1\\ShallowMindBot.py\u001b[0m in \u001b[0;36mdoTurn\u001b[1;34m(self, api)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;31m# Store results of this step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'logs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'game_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'round_{}.pkl'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'round'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossible_action_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_type_probabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_type_choice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\logs\\\\game_-1\\\\round_74.pkl'"
     ]
    }
   ],
   "source": [
    "bot.doTurn(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_actions = [0,1,2,6]\n",
    "p, h = bot.policy_forward(bot.computeStateFeatures(api), possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_action = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POSSIBLE_ACTIONS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_grad(softmax):\n",
    "    s = softmax.reshape(-1,1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([float(val) for val in bot.computeStateFeatures(api).values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradW2(p, possible_actions, selected_action, h):\n",
    "    dsoftmax = softmax_grad(p)[selected_action,:]\n",
    "    dlog = dsoftmax / p[selected_action]\n",
    "    # Fill in dlog with zeros at the actions that were not possible\n",
    "    dlog_filled = np.zeros(NUM_ACTION_TYPES)\n",
    "    dlog_filled[possible_actions] = dlog\n",
    "    dW2 = dlog_filled[None,:].T.dot(h[None,:])\n",
    "    return dW2, dlog_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-5363ce444d62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgradW2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlog_filled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradW2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossible_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "gradW2, dlog_filled = gradW2(p, possible_actions, selected_action, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradW1(dlog_filled, W2, h, x):\n",
    "    dh = W2.T.dot(dlog_filled)\n",
    "    dh[h<=0] = 0\n",
    "    dW1 = np.outer(dh,x)\n",
    "    return dW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradw1 = gradW1(dlog_filled, bot.model['W2'], h, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1\n",
    "batch_size = 100 # used to perform a RMS prop param update every batch_size steps\n",
    "learning_rate = 1e-2 # learning rate used in RMS prop\n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "reward_win = 10**5\n",
    "reward_lose = -reward_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx in range(num_batches):\n",
    "    # Clear out the logs folder\n",
    "    log_subfolders = [d for d in os.listdir(os.path.join('.','logs')) if os.path.isdir(os.path.join('.','logs',d))]\n",
    "    for subfolder in log_subfolders:\n",
    "        shutil.rmtree(os.path.join('.','logs',subfolder))\n",
    "        \n",
    "    # Run the games in the batch\n",
    "    for game_idx in range(batch_size):\n",
    "        ! java -jar tower-defence-runner-3.0.3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won 87 of 100 games\n"
     ]
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "\n",
    "model_params = pickle.load(open('model_params.p','rb'))\n",
    "\n",
    "advantages = []\n",
    "win_count = 0\n",
    "for game_idx in range(batch_size):\n",
    "    num_rounds = max([int(f.split('.')[0].split('_')[1]) for f in os.listdir(os.path.join('.','logs','game_{}'.format(game_idx)))])\n",
    "    rewards = np.zeros(num_rounds)\n",
    "    for round_idx in range(num_rounds):\n",
    "        with open(os.path.join('.','logs','game_{}'.format(game_idx),'round_{}.pkl'.format(round_idx)), 'rb') as f:\n",
    "            state_features, possible_action_types, action_type_probabilities, hidden_layer, action_type_choice = pickle.load(f)\n",
    "        rewards[round_idx] = state_features['myMinusOppScore']\n",
    "        # If last round, estimate who won or lost and update rewards\n",
    "        if round_idx == (num_rounds-1):\n",
    "            if state_features['myMinusOppHealth'] > 0:\n",
    "                rewards[round_idx] += reward_win\n",
    "                win_count += 1\n",
    "            else:\n",
    "                rewards[round_idx] += reward_lose\n",
    "    \n",
    "    # Compute advantages\n",
    "    advantages.append(np.cumsum(rewards[::-1])[::-1])\n",
    "    \n",
    "print('Won {} of {} games'.format(win_count, batch_size))\n",
    "    \n",
    "# Standardize advantages\n",
    "advantages_all = np.hstack(advantages)\n",
    "advantages_mean = np.mean(advantages_all)\n",
    "advantages_std = np.std(advantages_all)\n",
    "\n",
    "# Compute gradients\n",
    "gW1 = np.zeros_like(bot.model['W1'])\n",
    "gW2 = np.zeros_like(bot.model['W2'])\n",
    "for game_idx in range(batch_size):\n",
    "    num_rounds = max([int(f.split('.')[0].split('_')[1]) for f in os.listdir(os.path.join('.','logs','game_{}'.format(game_idx)))])\n",
    "    # Increment gradients\n",
    "    advantages_game = advantages[game_idx]\n",
    "    for round_idx in range(num_rounds):\n",
    "        with open(os.path.join('.','logs','game_{}'.format(game_idx),'round_{}.pkl'.format(round_idx)), 'rb') as f:\n",
    "            state_features, possible_action_types, action_type_probabilities, hidden_layer, action_type_choice = pickle.load(f)\n",
    "        action_type_choice_idx = np.where(np.array(possible_action_types)==action_type_choice)[0][0]\n",
    "        gW2_round, dlog_filled = gradW2(action_type_probabilities, possible_action_types, action_type_choice_idx, hidden_layer)\n",
    "        gW2 += gW2_round*((advantages_game[round_idx]-advantages_mean)/advantages_std)\n",
    "        x = np.array([float(val) for val in state_features.values()])\n",
    "        gW1 += gradW1(dlog_filled, model_params['W2'], hidden_layer, x)*((advantages_game[round_idx]-advantages_mean)/advantages_std)\n",
    "    \n",
    "# Normalize by number of games\n",
    "gW1 /= batch_size\n",
    "gW2 /= batch_size\n",
    "\n",
    "# Update using gradient\n",
    "new_W1 = model_params['W1'] + learning_rate*gW1\n",
    "new_W2 = model_params['W2'] + learning_rate*gW2\n",
    "\n",
    "# Save\n",
    "new_model = {}\n",
    "new_model['W1'] = new_W1\n",
    "new_model['W2'] = new_W2\n",
    "pickle.dump(new_model,open('new_model_params.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.41082641e-04,  6.51927495e-03,  4.11334811e-04,\n",
       "         8.28630276e-03,  2.60915885e-03,  5.11966236e-03,\n",
       "         5.20450526e-03,  6.56597575e-03,  5.11487042e-05,\n",
       "         2.43740141e-03,  2.26086860e-04,  2.84756261e-04,\n",
       "         1.33638345e-03,  1.55448610e-03,  6.25835795e-03],\n",
       "       [-5.07853872e-04, -4.06885748e-03, -2.10988130e-04,\n",
       "        -4.62132145e-03, -1.99593926e-03, -1.68583677e-03,\n",
       "        -2.21045919e-03, -2.36700023e-03, -1.10134772e-05,\n",
       "        -1.37795554e-03,  7.37375012e-05, -8.15793976e-05,\n",
       "        -2.95547360e-03, -5.84644797e-04, -5.18787924e-03],\n",
       "       [ 2.56561847e-03,  4.25083314e-03, -2.30839233e-04,\n",
       "         1.06696587e-04,  8.84256525e-04,  7.02557352e-04,\n",
       "         1.84377926e-03,  2.88809922e-04,  2.10527297e-06,\n",
       "         4.30555867e-03,  2.55806576e-03,  5.92686395e-04,\n",
       "         7.84332032e-03,  7.13145840e-04,  4.39236115e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.46287973e-04,  5.93964890e-04,  1.40851213e-04,\n",
       "         2.43026643e-03,  8.06156764e-04,  7.98706780e-04,\n",
       "         6.49487528e-04,  1.86946125e-03, -2.06420666e-05,\n",
       "         4.22304304e-04, -4.09260529e-04, -2.69945056e-04,\n",
       "         1.60717701e-04,  4.47573992e-04,  1.04787782e-03],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-2.85255927e-03, -7.29521549e-03, -1.10358662e-04,\n",
       "        -6.20194433e-03, -2.30363287e-03, -4.93508972e-03,\n",
       "        -5.48731285e-03, -6.35724669e-03, -2.15984334e-05,\n",
       "        -5.78730885e-03, -2.44862959e-03, -5.25918202e-04,\n",
       "        -6.38494787e-03, -2.13056113e-03, -6.51071769e-03]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model['W2'] - model_params['W2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
