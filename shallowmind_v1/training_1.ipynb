{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShallowMindBot import *\n",
    "from TowerDefense import *\n",
    "from TowerDefenseApi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "towerDefense = TowerDefense('state.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TowerDefenseApi(towerDefense.getGameState())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ShallowMindBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected action type 4 from options [0, 1, 2, 4, 6] with probabilities [0.21018274 0.19952657 0.19744639 0.19700019 0.1958441 ]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\logs\\\\game_-1\\\\round_74.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dce77b876d8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoTurn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Nerdfest\\src\\shallowmind\\shallowmind_v1\\ShallowMindBot.py\u001b[0m in \u001b[0;36mdoTurn\u001b[1;34m(self, api)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;31m# Store results of this step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'logs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'game_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'round_{}.pkl'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'round'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossible_action_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_type_probabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_type_choice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\logs\\\\game_-1\\\\round_74.pkl'"
     ]
    }
   ],
   "source": [
    "bot.doTurn(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_actions = [0,1,2,6]\n",
    "p, h = bot.policy_forward(bot.computeStateFeatures(api), possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_action = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POSSIBLE_ACTIONS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_grad(softmax):\n",
    "    s = softmax.reshape(-1,1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([float(val) for val in bot.computeStateFeatures(api).values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradW2(p, possible_actions, selected_action, h):\n",
    "    dsoftmax = softmax_grad(p)[selected_action,:]\n",
    "    dlog = dsoftmax / p[selected_action]\n",
    "    # Fill in dlog with zeros at the actions that were not possible\n",
    "    dlog_filled = np.zeros(NUM_ACTION_TYPES)\n",
    "    dlog_filled[possible_actions] = dlog\n",
    "    dW2 = dlog_filled[None,:].T.dot(h[None,:])\n",
    "    return dW2, dlog_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradW2, dlog_filled = gradW2(p, possible_actions, selected_action, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradW1(dlog_filled, W2, h, x):\n",
    "    dh = W2.T.dot(dlog_filled)\n",
    "    dh[h<=0] = 0\n",
    "    dW1 = np.outer(dh,x)\n",
    "    return dW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradw1 = gradW1(dlog_filled, bot.model['W2'], h, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1\n",
    "batch_size = 100 # used to perform a RMS prop param update every batch_size steps\n",
    "learning_rate = 1e-3 # learning rate used in RMS prop\n",
    "gamma = 0.99 # discount factor for reward\n",
    "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
    "reward_win = 10**5\n",
    "reward_lose = -reward_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx in range(num_batches):\n",
    "    # Clear out the logs folder\n",
    "    log_subfolders = [d for d in os.listdir(os.path.join('.','logs')) if os.path.isdir(os.path.join('.','logs',d))]\n",
    "    for subfolder in log_subfolders:\n",
    "        shutil.rmtree(os.path.join('.','logs',subfolder))\n",
    "        \n",
    "    # Run the games in the batch\n",
    "    for game_idx in range(batch_size):\n",
    "        ! java -jar tower-defence-runner-3.0.3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "# Learn from the game outcomes: compute and execute gradient update of parameters\n",
    "gradW1 = np.zeros_like(bot.model['W1'])\n",
    "gradW2 = np.zeros_like(bot.model['W2'])\n",
    "for game_idx in range(batch_size):\n",
    "    num_rounds = max([int(f.split('.')[0].split('_')[1]) for f in os.listdir(os.path.join('.','logs','game_{}'.format(game_idx)))])\n",
    "    rewards = np.zeros(num_rounds)\n",
    "    for round_idx in range(num_rounds):\n",
    "        with open(os.path.join('.','logs','game_{}'.format(game_idx),'round_{}.pkl'.format(round_idx)), 'rb') as f:\n",
    "            state_features, possible_action_types, action_type_probabilities, hidden_layer, action_type_choice = pickle.load(f)\n",
    "        rewards[round_idx] = state_features['myMinusOppScore']\n",
    "        # If last round, estimate who won or lost and update rewards\n",
    "        if round_idx == (num_rounds-1):\n",
    "            if state_features['myMinusOppHealth'] > 0:\n",
    "                rewards[round_idx] += reward_win\n",
    "            else:\n",
    "                rewards[round_idx] += reward_lose\n",
    "    # Compute advantages\n",
    "    advantages = \n",
    "    # Update gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.,  2223.,  4394.,  6305.,  8141.,  9953., 11648., 13165.,\n",
       "       14642., 16095., 17443., 18527., 19601., 20648., 21676., 22472.,\n",
       "       23320., 24144., 24949., 25575., 26235., 26870., 27482., 27998.,\n",
       "       28501., 29056., 29582., 29984., 30378., 30754., 31117., 31312.,\n",
       "       31508., 31670., 31820., 31962., 32104., 32246., 32373., 32499.,\n",
       "       32608., 32734., 32842., 32941., 33042., 33143., 33234., 33316.,\n",
       "       33402., 33485., 33575., 33662., 33745., 33815., 33878., 33933.,\n",
       "       33986., 34033., 34073., 34107., 34132., 34148., 34156., 34165.,\n",
       "       34168., 34168., 34168., 34168., 34168., 34168., 34168., 34168.,\n",
       "       34168., 34168.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(rewards[::-1]) - rewards[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
